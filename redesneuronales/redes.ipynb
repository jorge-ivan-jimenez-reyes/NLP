{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-20T22:19:52.591100Z",
     "start_time": "2025-03-20T22:19:52.557086Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('clickbait_dataset.csv')\n",
    "df.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            headline  clickbait\n",
       "0  This Is What $1 USD Gets You In Food All Aroun...          1\n",
       "1  Make These Easy Chicken Fajita Quesadillas At ...          1\n",
       "2  The Hardest \"Walking Dead\" Video Game Quiz You...          1\n",
       "3  34 Online Shops Based In The Southeast You Sho...          1\n",
       "4  US and France to work together for new Iran sa...          0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>clickbait</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Is What $1 USD Gets You In Food All Aroun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Make These Easy Chicken Fajita Quesadillas At ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Hardest \"Walking Dead\" Video Game Quiz You...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34 Online Shops Based In The Southeast You Sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US and France to work together for new Iran sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T22:22:44.544621Z",
     "start_time": "2025-03-20T22:22:44.434519Z"
    }
   },
   "cell_type": "code",
   "source": "df = df.dropna()\n",
   "id": "feed999458a94f75",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "347787ddc135cf18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9c5f40de4dd24096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "embeddings ={}\n",
    "with open('/Users/jorgejimenez/Documents/UP/NLP/simcos/glove.42B.300d.txt', encoding='utf-8') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vectors = np.asarray(values[1:])\n",
    "    embeddings[word] = vectors"
   ],
   "id": "91cf58a1ba959881"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import contractions               #Won't -> will not\n",
    "import re                         #Regex\n",
    "import nltk                       #Tokenizar texto\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "stopwords_en = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tqdm.pandas()"
   ],
   "id": "1c2cfc483b0913d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def vectorize(texto):\n",
    "  vector_size = 300 #Dependiento del archivo de glove -> glove.6B.300d.txt\n",
    "\n",
    "  #Todo a minusculas\n",
    "  texto = texto.lower()\n",
    "\n",
    "  #Contracciones\n",
    "  texto = contractions.fix(texto)\n",
    "\n",
    "  #Regex para quitar todo lo que no sea letra\n",
    "  texto = re.sub(r'[^a-z\\s]','', texto)\n",
    "\n",
    "  #Quitar stop words\n",
    "  texto = word_tokenize(texto)\n",
    "\n",
    "  #Eliminar stopwords\n",
    "  texto = [token for token in texto if token not in stopwords_en]\n",
    "\n",
    "  #Lemmatizar\n",
    "  texto = [lemmatizer.lemmatize(word) for word in texto]\n",
    "\n",
    "  #Generar vector (sumar linealmente)\n",
    "  vector = np.zeros(vector_size)\n",
    "\n",
    "  for word in texto:\n",
    "    if word in embeddings:\n",
    "      vector += embeddings[word].astype(float)\n",
    "\n",
    "  vector = vector.reshape(1, -1)[0] #Una fila, columans necesarias\n",
    "\n",
    "  return vector"
   ],
   "id": "510f58d13c933145"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm import tqdm\n",
    "nltk.download"
   ],
   "id": "1243a5c11e8e0870"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
