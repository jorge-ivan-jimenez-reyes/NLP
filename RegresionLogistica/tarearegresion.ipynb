{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-14T05:46:00.337324Z",
     "start_time": "2025-02-14T05:45:58.670438Z"
    }
   },
   "source": [
    "! pip install contractions\n",
    "! pip install punktab"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /opt/anaconda3/lib/python3.12/site-packages (0.1.73)\r\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /opt/anaconda3/lib/python3.12/site-packages (from contractions) (0.0.24)\r\n",
      "Requirement already satisfied: anyascii in /opt/anaconda3/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\r\n",
      "Requirement already satisfied: pyahocorasick in /opt/anaconda3/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\r\n",
      "\u001B[31mERROR: Could not find a version that satisfies the requirement punktab (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for punktab\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-14T05:48:50.718302Z",
     "start_time": "2025-02-14T05:48:50.561452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import contractions\n",
    "import re\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.util import ngrams"
   ],
   "id": "d722fd36ef4ab6a1",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwordcloud\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m WordCloud\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ngrams\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv('/Users/jorgejimenez/Documents/UP/NLP/RegresionLogistica/deepsea.csv')\n",
    "df.head()"
   ],
   "id": "4aec39472249f07e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ],
   "id": "f9f856c297365cfe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mapper = {\n",
    "    'biology': 0,\n",
    "    'meme': 1\n",
    "}\n",
    "df['etiqueta'] = df['category'].map(mapper)\n",
    "df.head()"
   ],
   "id": "a1ef6318469c00e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def procesamiento_de_texto(texto):\n",
    "  #Arreglar contracciones:\n",
    "  texto = contractions.fix(texto)\n",
    "  #Hacer todo minusculo\n",
    "  texto = texto.lower()\n",
    "  #Regex\n",
    "  texto = re.sub(r'[^a-z\\s]', '', texto)\n",
    "  #Tokenizar\n",
    "  texto = word_tokenize(texto)\n",
    "  #Quitar stopwords\n",
    "  texto = [token for token in texto if token not in stop_words]\n",
    "  #Lemmatizar\n",
    "  texto = [lemmatizer.lemmatize(word) for word in texto]\n",
    "  #Juntar todo\n",
    "  texto = ' '.join(texto)\n",
    "  # Regresar resultado\n",
    "  return texto"
   ],
   "id": "5e98b2226ecb806"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "tqdm.pandas()",
   "id": "fa8969e4606ddc8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['clean_tweet'] =  df['tweet'].progress_apply(procesamiento_de_texto)\n",
    "df.head()"
   ],
   "id": "7ce2e79dc4a11bd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def generate_ngrams(n, arreglo):\n",
    "  x = []\n",
    "  for texto in arreglo:\n",
    "    n_grams = ngrams(word_tokenize(texto), n)\n",
    "    for grams in n_grams:\n",
    "      resultado = ' '.join(grams)\n",
    "      x.append(resultado)\n",
    "  return pd.Series(x).value_counts()"
   ],
   "id": "3775d29ce5fa87de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "n = 2\n",
    "cym_ngrams = generate_ngrams(n, df['clean_tweet']).head(30)\n",
    "cym_ngrams.head(10)"
   ],
   "id": "2289ee6bf995de89"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data=cym_ngrams\n",
    "plt.barh(data.index, data.values)\n",
    "plt.xlabel('Frecuencia')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()"
   ],
   "id": "b104f03c60cfee9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nube=WordCloud(width=2000, height=2000, colormap='Wistia_r', background_color='black',min_font_size=8).generate_from_frequencies(cym_ngrams)",
   "id": "9d3d94ba263ccd7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(nube)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cf6dbf994eca3045"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ngram with meme only\n",
    "n = 2\n",
    "cym_ngrams = generate_ngrams(n, df[df['category'] == 'meme']['clean_tweet']).head(30)\n",
    "cym_ngrams.head(10)"
   ],
   "id": "94510080e071f46c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data=cym_ngrams\n",
    "plt.barh(data.index, data.values)\n",
    "plt.xlabel('Frecuencia')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()"
   ],
   "id": "c7391a0939066c77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nube=WordCloud(width=2000, height=2000, colormap='Wistia_r', background_color='black',min_font_size=8).generate_from_frequencies(cym_ngrams)",
   "id": "3cd756481d95a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(nube)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "362c26b91f55e8e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    " # ngram with biology only\n",
    " n = 2\n",
    "cym_ngrams = generate_ngrams(n, df[df['category'] == 'biology']['clean_tweet']).head(30)\n",
    "cym_ngrams.head(10)"
   ],
   "id": "550b995f806422eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "nube=WordCloud(width=2000, height=2000, colormap='Wistia_r', background_color='black',min_font_size=8).generate_from_frequencies(cym_ngrams)",
   "id": "7f3970dc6bea16bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(nube)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "c5194591810a05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tdidf_vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "vectorized_tweets = tdidf_vectorizer.fit_transform(df['clean_tweet'])\n",
    "vectorized_tweets"
   ],
   "id": "7384216e4161a7f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.manifold import TSNE\n",
    "model = TSNE(n_components=2, init='random')\n",
    "tsne_result = model.fit_transform(vectorized_tweets)\n",
    "tsne_result"
   ],
   "id": "878107e13000cb95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['tsne_1'] = tsne_result[:,0]\n",
    "df['tsne_2'] = tsne_result[:,1]"
   ],
   "id": "dc66d3f51ebf3fb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(\n",
    "    data_frame=df,\n",
    "    x=df['tsne_1'],\n",
    "    y=df['tsne_2'],\n",
    "    color=df['etiqueta'],\n",
    "    template='plotly_dark',\n",
    "    hover_data=['tweet']\n",
    ")\n",
    "fig.show()"
   ],
   "id": "cc34ea8cce4264c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df['clean_tweet']\n",
    "Y = df['etiqueta']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7, random_state=101)"
   ],
   "id": "5e8f3810773435f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "#Fit transform en datos de entrenamiento\n",
    "X_train_vectorized = tfidf.fit_transform(X_train)\n",
    "\n",
    "#Transform en datos de prueba\n",
    "X_test_vectorized = tfidf.transform(X_test)"
   ],
   "id": "48649cc324ae046e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_vectorized, Y_train)"
   ],
   "id": "c1c3a20df267542d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_pred = model.predict(X_test_vectorized)",
   "id": "126298390a3939d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_pred",
   "id": "82c4370515893ce3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "Y_test",
   "id": "273be4bd4e13f04a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns"
   ],
   "id": "97bd1d2b94f153f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "sns.heatmap(confusion_matrix(Y_test,y_pred), annot=True, fmt='.2f')",
   "id": "52ec7d6ee6427c08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(classification_report(Y_test,y_pred))\n",
    "# precision me importan los falsos positivos\n",
    "# recall me importan los falsos negativos\n",
    "# f1-score me importa el overall de todo"
   ],
   "id": "e5c86e38d5c2c580"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
