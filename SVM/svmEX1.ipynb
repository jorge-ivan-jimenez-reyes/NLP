{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-18T22:32:54.064008Z",
     "start_time": "2025-02-18T22:32:53.940673Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('deepsea.csv')\n",
    "df.head()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               tweet category\n",
       "0  Fascinating discovery! An abyssal fish species...  biology\n",
       "1  Deep sea fish really said 'surface world I'm c...     meme\n",
       "2  Research suggests rapid vertical migration mig...  biology\n",
       "3  lmao this fish literally speedran evolving to ...     meme\n",
       "4  The vertical migration observed in this abyssa...  biology"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fascinating discovery! An abyssal fish species...</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deep sea fish really said 'surface world I'm c...</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Research suggests rapid vertical migration mig...</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lmao this fish literally speedran evolving to ...</td>\n",
       "      <td>meme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The vertical migration observed in this abyssa...</td>\n",
       "      <td>biology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T22:33:10.541974Z",
     "start_time": "2025-02-18T22:33:09.044931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "stopwords_en = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ],
   "id": "921f5a2d5e655ff0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jorgejimenez/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jorgejimenez/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jorgejimenez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mapper = {\n",
    "    1: 'Suicide',\n",
    "    0: 'Non-suicide'\n",
    "}\n",
    "df['etiqueta'] = df['intention'].map(mapper)\n",
    "df.head()"
   ],
   "id": "e906949e8ff0c6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import contractions\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def preprocesamiento_texto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = contractions.fix(texto)\n",
    "    texto = re.sub(r'[^a-z\\s]','', texto)\n",
    "    texto_tokenized = word_tokenize(texto)\n",
    "    texto_no_stop = [token for token in texto_tokenized if token not in stopwords_en]\n",
    "    final = [lemmatizer.lemmatize (word) for word in texto_no_stop]\n",
    "    final = ' '.join(final)\n",
    "    return final"
   ],
   "id": "5e9a798c9b03c4e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df['clean_tweet'] = df['tweet'].progress_apply(preprocesamiento_texto)\n",
    "df.head()"
   ],
   "id": "b551a0caec166bf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x = df['clean_tweet']\n",
    "y = df['intention']"
   ],
   "id": "b8dfce9bc7797a02"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
